<!DOCTYPE html>
<html lang="en">
    
    <head>
        
        <meta charset="utf-8">
            <meta http-equiv="X-UA-Compatible" content="IE=edge">
                <meta name="viewport" content="width=device-width, initial-scale=1">
                    <meta name="description" content="">
                        <meta name="author" content="">
                            
                            <title>Himanshu Tyagi - Homepage</title>
                            
                            <!-- Bootstrap Core CSS -->
                            <link href="css/bootstrap.min.css" rel="stylesheet">
                                
                                <!-- Custom CSS -->
                                <link href="css/customized.css" rel="stylesheet">
                                    
                                    <!-- HTML5 Shim and Respond.js IE8
                                    support of HTML5 elements and
                                    media queries --> <!-- WARNING:
                                    Respond.js doesn't work if you
                                    view the page via file:// -->
                                    <!--[if lt IE 9]>
                                     <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
                                     <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
                                     <![endif]-->
                                    <link rel="shortcut icon" href="favicon.ico" type="image/icon">
                                    <link rel="icon" href="favicon.ico" type="image/icon">


    </head>
    
    <body id="page-top"  data-spy="scroll" data-target=".navbar-fixed-top">
        
        <!-- Navigation -->
        <nav class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">
                <div class="navbar-header page-scroll">
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-ex1-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand page-scroll"
                    href="#page-top" style="color:#222">Himanshu
                    Tyagi</a>
                </div>
                
                <!-- Collect the nav links, forms, and other content
                for toggling -->
                <div class="collapse navbar-collapse navbar-ex1-collapse">
                    <ul class="nav navbar-nav">
                        <!-- Hidden li included to remove active class
                        from about link when scrolled up past about
                        section -->
                        <li class="hidden">
                            <a href="#page-top"></a>
                        </li>
                    </ul>
                    <ul class="nav navbar-nav navbar-left">


                        <li>
                            <a data-toggle="collapse"
                            data-target=".navbar-collapse"
                            class="page-scroll"
                            href="#courses">Courses</a>
                        </li>


                        <li class="dropdown">
                            <a class="dropdown-toggle"
                            data-toggle="dropdown" role="button"
                            aria-haspopup="true"
                            aria-expanded="false">Publications
                                <span class="caret"></span>
                            </a>
                            <ul class="dropdown-menu">
                                <li>
                                    <a data-toggle="collapse"
                                    data-target=".navbar-collapse"
                                    class="page-scroll"
                                    href="#preprints">Preprints</a>
                                </li>


                                
                                <li>
                                    <a data-toggle="collapse"
                                    data-target=".navbar-collapse"
                                    class="page-scroll"
                                    href="#journal-papers">Journal
                                    Papers</a>
                                </li>

                                <li>
                                    <a data-toggle="collapse"
                                    data-target=".navbar-collapse"
                                    class="page-scroll"
                                    href="#monograph">Monographs</a>
                                </li>


                                <li>
                                    <a data-toggle="collapse"
                                    data-target=".navbar-collapse"
                                    class="page-scroll"
                                    href="#conference-papers">Conference
                                    Proceedings</a>
                                </li>
                                <li>
                                    <a data-toggle="collapse"
                                    data-target=".navbar-collapse"
                                    class="page-scroll"
                                    href="#theses">Theses</a>
                                </li>
                            </ul>
                        </li>
                    

                        <li>
                            <a data-toggle="collapse"
                            data-target=".navbar-collapse"
                            class="page-scroll"
                            href="#group">Group</a>
                        </li>


                        <li>
                            <a data-toggle="collapse"
                            data-target=".navbar-collapse"
                            class="page-scroll"
                            href="#students">Prospective Students</a>
                        </li>
                        <li>
                            <a data-toggle="collapse"
                            data-target=".navbar-collapse"
                            class="page-scroll"
                            href="#talks">Talks</a>
                        </li>





                    </ul>
                </div>
            </div>
            <!-- /.container -->
        </nav>
        
        
        <!-- Intro Section -->
        <section id="intro" class="intro-section">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-2 col-lg-offset-2">
                        <img src="img/tyagi.jpg" class="profile-img">
                            </div>
                    <div class="col-lg-6 col-lg-offset-2 profile">
                        <dt>Affiliation</dt>
                        <dd>
                            <ul style="list-style-type:none;">
                                <li>Assistant Professor</li>
                                <li> <a href="http://www.ece.iisc.ernet.in"
                                target="_blank"> Department of
                                Electrical Communication
                                Engineering </a></li>
                                <li><a href="http://www.iisc.ernet.in"
                                target="_blank"> Indian Institute of
                                Science </a></li>
                                <li>Bangalore - 560012, India</li>
                                <li>Office: SP 1.01</li>
                            </ul>
                        </dd>
                        <dt> Contact </dt>
                        <dd>
                            <ul style="list-style-type:none">
                                <li>Phone: +91 80 2293-2277</li>
                                <li>Email:
                                htyagi@iisc.ac.in</li>
                                
                            </ul>
                        </dd>
                        <dt>Academic Experience</dt>
                        <dd>
                            <ul style="list-style-type:none">
                                <li>Postdoc at the ITA center, UCSD
                                (2014)</li>
                                <li>Ph.D. in ECE, UMD (2013)</li>
                                <li>Dual degree in EE, IIT Delhi
                                (2007)</li>
                            </ul>
                        </dd>
                        
                    </div>
                    
                </div>
            </div>
        </section>
                
        <!-- Teaching -->
        <section id="courses" class="courses">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Courses</h2>
                        <ul>



			    <li> Jan-May 2018: Topics in Information Theory and Statistical Learning <a href="course-E2209-2018.html"
			    target="_blank">[website]</a>
			      </li>
			    <li> Aug-Dec 2016, 2017: Concentration
			    Inequalities  <a href="course-E2207-2017.html"
			    target="_blank">[website]</a>
			      </li>

		    <li> Jan-May 2016, 2017: Information and Communication
		    Complexity <a href="course-E2206-2017.html"
			    target="_blank">[website]</a>
                            </li>
			    <li> Aug-Dec 2015, 2016: Information Theory
			     <a href="course-E2201-2016.html"
			    target="_blank">[website]</a>
			      </li>
                        </ul>
                        <hr>
                    </div>
                </div>
            </div>
        </section>


        
        
        <!-- Publications -->
        <section class="publications">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Publications</h2>
                    </div>
                </div>
                <div id="preprints" class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Preprints</h2>
                        <dd>
                            <ul>
                                <li>With S. Watanabe, Strong Converse                              using Measure Change Arguments.   <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/ht-sw18ii.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
The strong converse for a coding theorem shows that the optimal
asymptotic rate possible with vanishing error cannot be improved by
allowing a fixed error. Building on a method introduced by Gu and
Effros for centralized coding problems, we develop a general and
simple recipe for proving strong converse that is applicable for
distributed problems as well. Heuristically, our proof of strong
converse mimics the standard steps for proving a weak converse, except
that we apply those steps to a modified distribution obtained by
conditioning the original distribution on the event that no error
occurs. A key component of our recipe is the replacement of the hard
Markov constraints implied by the distributed nature of the problem
with a soft information cost using a variational formula introduced by
Oohama. We illustrate our method by providing a short proof of the
strong converse for the Wyner-Ziv problem and new strong converse
theorems for interactive function computation, common randomness and
secret key agreement, and the wiretap channel. 
                                    </p>
                                </li> 

                                <li>With J. Acharya and C. Canonne,
                                Distributed Simulation and Distributed
                                Inference.   <br /> 
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/ja-cc-ht18.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
  Independent samples from an unknown probability distribution $\p$ on a
domain of size $\ab$ are distributed across $\ns$ players, with each
player holding one sample. Each player can communicate $\ell$ bits to
a central referee in a simultaneous message passing (SMP) model of
communication to help the referee infer a property of the unknown $\p$. 
When $\ell\geq\log \ab$ bits, the problem reduces to the
well-studied collocated
case where all the samples are available in
one place. In this work, we focus on the communication-starved setting of 
$\ell < \log \ab$, in which the landscape may change drastically. We
propose a general formulation for inference problems in this
distributed setting, and instantiate it to two prototypical inference
questions: Learning and uniformity testing.  
                                    </p>
                                </li>  


</ul>
                        </dd>
                    </div>
                </div>

                <div id="journal-papers" class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Journal Papers</h2>
                        <dd>
                            <ul>


                                <li>
                                    With P. Viswanath and S. Watanabe,
                                    Interactive Communication for Data
                                    Exchange.
<i> IEEE Transactions on Information Theory,  vol. 64, no. 1, 2018.</i><br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/HT-PV-SW17.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    Two parties observing correlated
                                    data seek to exchange their data
                                    using interactive
                                    communication. How many bits must
                                    they communicate? We propose a new
                                    interactive protocol for data
                                    exchange which increases the
                                    communication size in steps until
                                    the task is done. We also derive a
                                    lower bound on the minimum number
                                    of bits that is based on relating
                                    the data exchange problem to the
                                    secret key agreement problem. Our
                                    single-shot analysis applies to
                                    all discrete random variables and
                                    yields upper and lower bounds of a
                                    similar form. In fact, the bounds
                                    are asymptotically tight and lead
                                    to a characterization of the
                                    optimal rate of communication
                                    needed for data exchange for a
                                    general source sequence such as a
                                    mixture of IID random variables as
                                    well as the optimal second-order
                                    asymptotic term in the length of
                                    communication needed for data
                                    exchange for IID random variables,
                                    when the probability of error is
                                    fixed. This gives a precise
                                    characterization of the asymptotic
                                    reduction in the length of optimal
                                    communication due to interaction;
                                    in particular, two-sided
                                    Slepian-Wolf compression is
                                    strictly suboptimal.
                                    </p>
                                </li>


 <li>
                                                                        With S. Venkatakrishnan,
                                    P. Viswanath, and S. Watanabe,
                                    Information Complexity Density and
                                    Simulation of Protocols.
<i> IEEE Transactions on Information Theory,  vol. 63, no. 11, 2017.</i><br />                                    <abstract><a>[Abstract]</a></abstract> <a href="papers/HTSVPVSW17-jrnl.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A simulation of an interactive
                                    protocol entails the use of
                                    interactive communication to
                                    produce the output of the protocol
                                    to within a fixed statistical
                                    distance $\epsilon$.  Recent works
                                    have proposed that the information
                                    complexity of the protocol plays a
                                    central role in characterizing the
                                    minimum number of bits that the
                                    parties must exchange for a
                                    successful simulation, namely the
                                    distributional communication
                                    complexity of simulating the
                                    protocol. Several simulation
                                    protocols have been proposed with
                                    communication complexity depending
                                    on the information complexity of
                                    the simulated protocol.  However,
                                    in the absence of any general
                                    lower bounds for distributional
                                    communication complexity, the
                                    conjectured central role of
                                    information complexity is far from
                                    settled.  We fill this gap and
                                    show that the distributional
                                    communication complexity of
                                    $\epsilon$-simulating a protocol
                                    is bounded below by the
                                    $\epsilon$-tail $\lambda_\epsilon$
                                    of the information complexity
                                    density, a random variable with
                                    information complexity as its
                                    expected value. For protocols with
                                    bounded number of rounds, we give
                                    a simulation protocol that yields
                                    a matching upper bound.  Thus, it
                                    is not information complexity but
                                    $\lambda_\epsilon$ that governs
                                    the distributional communication
                                    complexity.
                                    
                                    As applications of our bounds, in
                                    the amortized regime for product
                                    protocols, we identify the exact
                                    second order term, together with
                                    the precise dependence on
                                    $\epsilon$. For general protocols
                                    such as a mixture of two product
                                    protocols or for the amortized
                                    case when the repetitions are not
                                    independent, we derive a general
                                    formula for the leading asymptotic
                                    term. These results sharpen and
                                    significantly extend known results
                                    in the amortized regime. In the
                                    single-shot regime, our lower
                                    bound clarifies the dependence of
                                    communication complexity on
                                    $\epsilon$. We illustrate this
                                    with an example that exhibits an
                                    arbitrary separation between
                                    distributional communication
                                    complexity and information
                                    complexity for all sufficiently
                                    small $\epsilon$.
                                    </p>
                                </li>
                                  


                              <li>
                                    
                                    With S. Watanabe, Universal
				    Multiparty Data Exchange and
				    Secret Key Agreement.
                                    <i> IEEE Transactions
                                    on Information Theory,  vol. 63, no. 7, 2017.</i><br />
                                    <abstract><a>[Abstract]</a></abstract> <a href="papers/HTSW17-jrnl.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text"> Multiple
parties observing correlated data seek to recover each other’s data
and attain omniscience. To that end, they communicate interactively
over a noiseless broadcast channel: Each bit transmitted over this
channel is received by all the parties. We give a universal
interactive communication protocol for omniscience which requires
communication of rate only $\mathcal{O}\left(n^{−1/2}\sqrt{\log
n}\right)$ more than the optimal rate for every independent and
identically distributed (in time) sequence of data. Drawing on the
duality between omniscience and secret key agreement due to
Csisz&aacute;́r and Narayan, as a by-product, we obtain a universal
protocol for generating a multiparty secret key of rate at most
$\mathcal{O}\left(n^{−1/2}\sqrt{\log n}\right)$ less than the maximum
rate possible.

                                    </p>
                                </li>


			      <li> With J. Acharya, A. Orlitsky, and
                                    A. T. Suresh, Estimating Renyi
                                    Entropy of Discrete Distributions.                                   <i> IEEE Transactions
                                    on Information Theory vol. 63,
                                    no. 1, 2017. </i> <br/ >
                                    <abstract><a>[Abstract]</a></abstract> <a href="papers/AcharyaOST16.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                        
                                        It was shown recently that
                                        estimating the Shannon entropy
                                        $H(p)$ of a           
discrete $k$-symbol distribution $p$ requires $\Theta(k/\log k)$
                                        samples,       
a number that grows near-linearly in the support size.                          
In many applications $H(p)$ can be replaced by                                  
the more general R&egrave;nyi entropy of order $\alpha$, $H_\alpha(p)$.               
We determine the number of samples needed to estimate $H_\alpha(p)$                                        for all $\alpha$, showing that $\alpha < 1$                                     
requires a super-linear, roughly $k^{1/\alpha}$ samples,                         
noninteger $\alpha>1$ requires a near-linear $k$ samples,
but, perhaps surprisingly, integer $\alpha>1$ requires only
$\Theta(k^{1-1/\alpha})$ samples.
Furthermore, developing on a recently established connection between
                                        polynomial a\
pproximation
and estimation of additive functions of the form $\sum_xf (p_x)$, we
                                        reduce the \
sample complexity
for noninteger values of $\alpha$ by a factor of $\log k$ compared to
the empirical estimator.
The estimators achieving these
bounds are simple and run in time linear in the number of samples.
Our lower bounds provide explicit
  constructions of distributions with different R&egrave;nyi entropies that
                                        are
 hard to distinguish.                                        
                                        </p>
                                        </li>
                               

                                <li> With M. Hayashi and S. Watanabe,
                                    Secret Key Agreement: General
                                    Capacity and Second-Order
                                    Asymptotics.
                                     <i> IEEE Transactions on
                                    Information Theory vol. 62, no. 7,
                                    2016. </i> <br/ >
                                    <abstract><a>[Abstract]</a></abstract> <a href="papers/mh-ht-sw14.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    
                                    We revisit the problem of secret
                                    key agreement using interactive
                                    public communication for two
                                    parties and propose a new secret
                                    key agreement protocol. The
                                    protocol attains the secret key
                                    capacity for general observations
                                    and attains the second-order
                                    asymptotic term in the maximum
                                    length of a secret key for
                                    independent and identically
                                    distributed observations.  In
                                    contrast to the previously
                                    suggested secret key agreement
                                    protocols, the proposed protocol
                                    uses interactive communication.
                                    In fact, the standard one-way
                                    communication protocol used prior
                                    to this work fails to attain the
                                    asymptotic results above.  Our
                                    converse proofs rely on a recently
                                    established upper bound for secret
                                    key lengths.  Both our lower and
                                    upper bounds are derived in a
                                    single-shot setup and the
                                    asymptotic results are obtained as
                                    corollaries.
                                    
                                    </p>
                                </li>
 

<li> With A. Vardy, Universal Hashing for Information Theoretic
Security.
                                    <i> Proceedings of the IEEE
                                    vol. 103, no. 10, 2015.</i><br />
                                    <abstract><a>[Abstract]</a></abstract> <a href="papers/ht-av15.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    The information theoretic approach
                                    to security entails harnessing the
                                    correlated randomness available in
                                    nature to establish security. It
                                    uses tools from information theory
                                    and coding and yields provable
                                    security, even against an
                                    adversary with unbounded
                                    computational power. However, the
                                    feasibility of this approach in
                                    practice depends on the
                                    development of efficiently
                                    implementable schemes. In this
                                    article, we review a special class
                                    of practical schemes for
                                    information theoretic security
                                    that are based on 2-universal hash
                                    families. Specific cases of secret
                                    key agreement and wiretap coding
                                    are considered, and general themes
                                    are identified. The scheme
                                    presented for wiretap coding is
                                    modular and can be implemented
                                    easily by including an extra
                                    pre-processing layer over the
                                    existing transmission codes.

                                    </p>
                                </li>

                                <li>
                                    With S. Watanabe, Converses for
                                    Secret Key Agreement and Secure
                                    Computing.
                                    <i> IEEE Transactions on
                                    Information Theory,</i> vol. 61,
                                    no. 9, 2015.<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-watanabe15.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We consider information theoretic
                                    secret key agreement and secure
                                    function computation by multiple
                                    parties observing correlated data,
                                    with access to an interactive
                                    public communication channel. Our
                                    main result is an upper bound on
                                    the secret key length, which is
                                    derived using a reduction of
                                    binary hypothesis testing to
                                    multiparty secret key
                                    agreement. Building on this basic
                                    result, we derive new converses
                                    for multiparty secret key
                                    agreement. Furthermore, we derive
                                    converse results for the oblivious
                                    transfer problem and the bit
                                    commitment problem by relating
                                    them to secret key
                                    agreement. Finally, we derive a
                                    necessary condition for the
                                    feasibility of secure computing by
                                    trusted parties that seek to
                                    compute a function of their
                                    collective data, using interactive
                                    public communication that by
                                    itself does not give away the
                                    value of the function. In many
                                    cases, we strengthen and improve
                                    upon previously known converse
                                    bounds. Our results are
                                    single-shot and do not assume that
                                    the observations are independent
                                    and identically distributed. For
                                    the case when the observations are
                                    indeed independent and identically
                                    distributed, we derive strong
                                    versions of previously known
                                    converses.
                                    </p>
                                </li>
                                

                                
                                <li>
                                    With P. Narayan, How Many Queries
                                    will Resolve Common Randomness?
                                    <i> IEEE Transactions on
                                    Information Theory, vol. 59,
                                    no. 9</i>, 2013.<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan12ii.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A set of m terminals, observing
                                    correlated signals, communicate
                                    interactively to generate common
                                    randomness for a given subset of
                                    them.  Knowing only the
                                    communication, how many direct
                                    queries of the value of the common
                                    randomness will resolve it? A
                                    general upper bound, valid for
                                    arbitrary signal alphabets, is
                                    developed for the number of such
                                    queries by using a query strategy
                                    that applies to all common
                                    randomness and associated
                                    communication. When the underlying
                                    signals are independent and
                                    identically distributed
                                    repetitions of m correlated random
                                    variables, the number of queries
                                    can be exponential in signal
                                    length. For this case, the
                                    mentioned upper bound is tight and
                                    leads to a single-letter formula
                                    for the largest query exponent,
                                    which coincides with the secret
                                    key capacity of a corresponding
                                    multiterminal source model. In
                                    fact, the upper bound constitutes
                                    a strong converse for the optimum
                                    query exponent, and implies also a
                                    new strong converse for secret key
                                    capacity. A key tool, estimating
                                    the size of a large probability
                                    set in terms of R&egrave;nyi
                                    entropy, is interpreted separately
                                    also as a lossless block coding
                                    result for general sources. As a
                                    particularization, it yields the
                                    classic result for a discrete
                                    memoryless source.
                                    </p>
                                </li>
                                <li>
                                    Common Information and Secret Key
                                    Capacity.<i> IEEE Transactions on
                                    Information Theory, vol. 59,
                                    no. 9</i>, 2013.<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/Tyagi12ii.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We study the generation of a
                                    secret key of maximum rate by a
                                    pair of terminals observing
                                    correlated sources and with the
                                    means to communicate over a
                                    noiseless public communication
                                    channel. Our main result
                                    establishes a structural
                                    equivalence between the generation
                                    of a maximum rate secret key and
                                    the generation of a common
                                    randomness that renders the
                                    observations of the two terminals
                                    conditionally independent. The
                                    minimum rate of such common
                                    randomness, termed {\it
                                    interactive common information},
                                    is related to Wyner's notion of
                                    common information, and serves to
                                    characterize the minimum rate of
                                    interactive public communication
                                    required to generate an optimum
                                    rate secret key. This
                                    characterization yields a
                                    single-letter expression for the
                                    aforementioned communication rate
                                    when the number of rounds of
                                    interaction are bounded. An
                                    application of our results shows
                                    that interaction does not reduce
                                    this rate for binary symmetric
                                    sources. Further, we provide an
                                    example for which interaction does
                                    reduce the rate of communication
                                    above. Also, certain invariance
                                    properties of common information
                                    quantities are established that
                                    may be of independent interest.
                                    </p>
                                </li>
                                <li>
                                    Distributed Function Computation
                                    with Confidentiality.
                                    <i> IEEE JSAC: In-Network Function
                                    Computation</i>, April 2013.<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/Tyagi12i.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A set of terminals observe
                                    correlated data and seek to
                                    compute functions of the data
                                    using interactive public
                                    communication. At the same time,
                                    it is required that the value of a
                                    private function of the data
                                    remains concealed from an
                                    eavesdropper observing this
                                    communication. In general, the
                                    private function and the functions
                                    computed by the nodes can be all
                                    different. We show that a class of
                                    functions are securely computable
                                    if and only if the conditional
                                    entropy of data given the value of
                                    private function is greater than
                                    the least rate of interactive
                                    communication required for a
                                    related multiterminal
                                    source-coding task. A
                                    single-letter formula is provided
                                    for this rate in special cases.
                                    </p>
                                </li>
                                <li>
                                    With P. Narayan, State Dependent
                                    Channels: Strong Converse and
                                    Bounds on Reliability Function.
                                    </a>
                                    <i> Excursions in Harmonic
                                    Analysis: Applied and Numerical
                                    Harmonic Analysis, Springer</i>,
                                    2013.<br/>
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan12.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text"> We
                                    consider an information theoretic
                                    model of a communication channel
                                    with a time-varying probability
                                    law.  Specifically, our model
                                    consists of a state
                                    dependent <i>discrete memoryless
                                    channel</i>, in which the
                                    underlying state process is
                                    independent and identically
                                    distributed with known probability
                                    distribution, and for which the
                                    channel output at any time instant
                                    depends on the inputs and states
                                    only through their current
                                    values. For this channel, we
                                    provide a strong converse result
                                    for its capacity, explaining the
                                    structure of optimal transmission
                                    codes. Exploiting this structure,
                                    we obtain upper bounds for the
                                    reliability function when the
                                    transmitter is provided channel
                                    state information causally and
                                    noncausally. Instrumental to our
                                    proofs is a new technical result
                                    which provides an upper bound on
                                    the rate of codes with codewords
                                    that are "conditionally typical
                                    over large <i>message
                                    dependent</i> subsets of a typical
                                    set of state sequences." This
                                    technical result is a
                                    nonstraightforward extension of an
                                    analogous result for a discrete
                                    memoryless channel without states;
                                    the latter provides a bound on the
                                    rate of a good code with codewords
                                    of a fixed composition. </p>
                                </li>
                                <li>
                                    With P. Narayan and P. Gupta, When
                                    is a Function Securely Computable?
                                    <i> IEEE Transactions on
                                    Information Theory, vol. 57,
                                    no. 10</i>, 2011.<br/>
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan-gupta11.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A subset of a set of terminals
                                    that observe correlated signals
                                    seek to compute a function of the
                                    signals using public
                                    communication. It is required that
                                    the value of the function be
                                    concealed from an eavesdropper
                                    with access to the
                                    communication. We show that the
                                    function is securely computable if
                                    and only if its entropy is less
                                    than the capacity of a new secrecy
                                    generation model, for which a
                                    single-letter characterization is
                                    provided.
                                    </p>
                                </li>
                                <li>
                                    With A. Tripathi, A Simple
                                    Criterion on Degree Sequences of
                                    Graphs.
                                    <i> Discrete Applied Mathematics
                                    156(18): 3513-3517</i>,
                                    2008.<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tripathi-tyagi08.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A finite sequence of nonnegative
                                    integers is called graphic if the
                                    terms in the sequence can be
                                    realized as the degrees of
                                    vertices of a finite simple
                                    graph. We present two new
                                    characterizations of graphic
                                    sequences. The first of these is
                                    similar to a result of
                                    Havel-Hakimi, and the second
                                    equivalent to a result of
                                    Erd&ouml;s and Gallai, thus
                                    providing a short proof of the
                                    latter result. We also show how
                                    some known results concerning
                                    degree sets and degree sequences
                                    follow from our results.
                                    </p>
                                </li>
                                
                            </ul>
                        </dd>
                    </div>
                </div>
                

                <div id="monograph" class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Monographs</h2>
                        <dd>
                            <ul>
 
			      <li> with Prakash
			      Narayan, <a href="http://dx.doi.org/10.1561/0100000072"
			      target="_blank"> Multiterminal Secrecy
			      by Public Discussion.</a> <i>Foundations
			      and Trends in Communications and
			      Information Theory </i>, 2016.<br />
 <a href="papers/PN-HT-NOW-final1.pdf"
                                    target="_blank">[pdf]</a>
				</li>
			      </ul>
			    </dd>
		    </div>
		</div>


                <div  id="conference-papers" class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Conference Proceedings</h2>
                        <dd>
                            <ul>

                              <li>With S. Watanabe, Strong Converse
                              using Measure Change
                              Arguments.  <i>ISIT</i>, 2018.
                              (included in the TPC choice
                              session)<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/HT-SW-isit18.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
The strong converse for a coding theorem shows that the optimal
asymptotic rate possible with vanishing error cannot be improved by
allowing a fixed error. Building on a method introduced by Gu and
Effros for centralized coding problems, we develop a general and
simple recipe for proving strong converse that is applicable for the
distributed problems as well. Heuristically, our proof of strong
converse mimics the standard steps for proving a weak converse, except
that we apply those steps to a modified distribution obtained by
conditioning the original distribution on the event that no error
occurs. A key component of our recipe is the replacement of the hard
Markov constraints with a soft information cost using a variational
formula introduced by Oohama. We illustrate our method by providing a
short proof of the strong converse for the Wyner- Ziv problem and a
strong converse theorem for the interactive function computation
problem; the latter result was not available prior to our work.
                                    </p>
                                </li>

                              <li>With P. Mayekar and P. Parag,
                              Optimal Lossless Source Codes for Timely
                              Updates.  <i>ISIT</i>, 2018.  (finalist
                              for the Student Best Paper Award)<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/PM-PP-HT-isit18.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
A transmitter observing a sequence of independent and identically
distributed random variables seeks to keep a receiver updated about
its latest observations. The receiver need not be apprised about each
symbol seen by the transmitter, but needs to output a symbol at each
time instant $t$. If at time $t$ the receiver outputs the symbol seen
by the transmitter at time $U(t)\leq t$, the age of information at the
receiver at time $t$ is $t-U(t)$. We study the design of lossless
source codes that enable transmission with minimum average age at the
receiver. We show that the asymptotic minimum average age can be
attained (up to a constant bits gap) by {Shannon codes for a tilted
version of the original pmf} generating the symbols, which can be
computed easily by solving an optimization problem. Underlying our
construction for minimum average age codes is a new variational
formula for integer moments of random variables, which may be of
independent interest.
                                    </p>
                                </li>


                              <li>With A. Jain, Effective Memory
                              Shrinkage in Estimation.  <i>ISIT</i>,
                              2018.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/AJ-HT-isit18.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
It is known that a processor with limited memory consisting of an
$m$-state machine can distinguish two coins with biases that differ by
$1/ m$. On the other hand, the best additive accuracy with which the
same processor can estimate the bias of a coin is only $1
/\sqrt{m}$. We demystify this apparent shrinkage in memory by showing
that for any such estimator using an $m$-state machine, there exist
two values of the bias that are $1/\sqrt{m}$ apart but for which the
effective number of states available to resolve them is only
$O(\sqrt{m})$. Building on this result, we show that the number of
bits of memory required to estimate a bias in the interval $(a,
a2^{\alpha})$ with a multiplicative accuracy of $2^{\pm\delta}$ is
$\log (\alpha/ {\delta^2})$, up to an additive constant.  In fact, we
show that the lower bound is attained by a {\em Gaussian counter},
namely a probabilistic counter whose stationary distribution has a
Gaussian form. This gives a precise characterization of
memory-complexity of bias estimation along with a heuristically
appealing family of optimal estimators. Underlying our results are new
bounds for estimation of the natural parameter of a discrete
exponential family, which maybe of independent interest.
                                    </p>
                                </li>


                              <li>
                                    With K.R. Sahasranand, Extra
                                    Samples can Reduce the
                                    Communication for Independence
                                    Testing.
                                    <i>ISIT</i>, 2018.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/krs-ht-isit18.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
Two parties observing sequences of bits want to determine if their
bits were generated independently or not. To that end, the first party
communicates to the second. A simple communication scheme involves
taking as few sample bits as determined by the sample complexity of
independence testing and sending it to the second party. But is there
a scheme that uses fewer bits of communication than the sample
complexity, perhaps by observing more sample bits? We show that the
answer to this question is in the affirmative when the joint
distribution is a binary symmetric source. More generally, for any
given joint distribution, we present a distributed independence test
that uses linear correlation between functions of the observed random
variables. Furthermore, we provide lower bounds for the general
setting that use hypercontractivity and reverse hypercontractivity to
obtain a measure change bound between the joint and the independent
distributions. The resulting bounds are tight for both a binary
symmetric source and a Gaussian symmetric source.
                                    </p>
                                </li>


                              <li>
                                    With S. Watanabe, Optimality of
                                    the Recursive Data Exchange
                                    Protocol.
                                    <i>ISIT</i>, 2017.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/ht-sw17.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
Multiple parties observe correlated data generated independent and
identically (in time) from a known joint distribution. Parties
communicate with each other interactively to enable each party to
recover the data observed by all the other parties and attain
omniscience. We characterize the asymptotic growth of the number of
bits of interactive communication required by the parties to attain
omniscience up to the second-order term. For the converse, we provide
a single-shot lower bound for the required number of bits of
communication, which yields the asymptotic result as a special
case. It is shown that the knowledge of the distribution can be used
to modify the recently proposed recursive universal data exchange
protocol to render it optimal up to the second-order term. As a
corollary, we provide a precise characterization of the reduction in
communication for omniscience due to interaction.
                                    </p>
                                </li>



                              <li>
                                    With S. Watanabe, Universal
				    Multiparty Data Exchange.
                                    <i>ISIT</i>, 2016.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/ht-sw16.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    Multiple parties observing
                                    correlated data seek to recover
                                    each other’s data and attain
                                    omniscience. To that end, they
                                    communicate interactively over a
                                    noiseless broadcast channel: Each
                                    bit transmitted over this channel
                                    is received by all the parties. We
                                    give a universal interactive
                                    protocol for omniscience which
                                    requires communication of rate
                                    only
                                    $\mathcal{O}\left(n^{−1/2}\sqrt{\log
                                    n}\right)$ more than the optimal
                                    rate for every independent and
                                    identically distributed (in time)
                                    sequence of data.
                                    </p>
                                </li>


                                <li>
                                    With S. Venkatakrishnan,
                                    P. Viswanath, and S. Watanabe,
                                    Information Complexity Density and
                                    Simulation of Protocols.
                                    <i>ITCS</i>, 2016.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/HTPVSVSW15.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A simulation of an interactive
                                    protocol entails the use of
                                    interactive communication to
                                    produce the output of the protocol
                                    to within a fixed statistical
                                    distance $\epsilon$.  Recent works
                                    have proposed that the information
                                    complexity of the protocol plays a
                                    central role in characterizing the
                                    minimum number of bits that the
                                    parties must exchange for a
                                    successful simulation, namely the
                                    distributional communication
                                    complexity of simulating the
                                    protocol. Several simulation
                                    protocols have been proposed with
                                    communication complexity depending
                                    on the information complexity of
                                    the simulated protocol.  However,
                                    in the absence of any general
                                    lower bounds for distributional
                                    communication complexity, the
                                    conjectured central role of
                                    information complexity is far from
                                    settled.  We fill this gap and
                                    show that the distributional
                                    communication complexity of
                                    $\epsilon$-simulating a protocol
                                    is bounded below by the
                                    $\epsilon$-tail $\lambda_\epsilon$
                                    of the information complexity
                                    density, a random variable with
                                    information complexity as its
                                    expected value. For protocols with
                                    bounded number of rounds, we give
                                    a simulation protocol that yields
                                    a matching upper bound.  Thus, it
                                    is not information complexity but
                                    $\lambda_\epsilon$ that governs
                                    the distributional communication
                                    complexity.
                                    
                                    As applications of our bounds, in
                                    the amortized regime for product
                                    protocols, we identify the exact
                                    second order term, together with
                                    the precise dependence on
                                    $\epsilon$. For general protocols
                                    such as a mixture of two product
                                    protocols or for the amortized
                                    case when the repetitions are not
                                    independent, we derive a general
                                    formula for the leading asymptotic
                                    term. These results sharpen and
                                    significantly extend known results
                                    in the amortized regime. In the
                                    single-shot regime, our lower
                                    bound clarifies the dependence of
                                    communication complexity on
                                    $\epsilon$. We illustrate this
                                    with an example that exhibits an
                                    arbitrary separation between
                                    distributional communication
                                    complexity and information
                                    complexity for all sufficiently
                                    small $\epsilon$.
                                    </p>
                                </li>

                                
                                <li>
                                    With P. Viswanath and S. Watanabe,
                                    Interactive Communication for Data
                                    Exchange.
                                    <i>ISIT</i>, 2015.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/ht-pv-sw15.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    Two parties observing correlated
                                    data seek to exchange their data
                                    using interactive
                                    communication. How many bits must
                                    they communicate?  We propose a
                                    new interactive protocol for data
                                    exchange which increases the
                                    communication size in steps until
                                    the task is done. Next, we derive
                                    a lower bound on the minimum
                                    number of bits that is based on
                                    relating the data exchange problem
                                    to the secret key agreement
                                    problem.  Our single-shot analysis
                                    applies to all discrete random
                                    variables and yields upper and
                                    lower bound of a similar form. In
                                    fact, the bounds are
                                    asymptotically tight and lead to a
                                    characterization of the optimal
                                    rate of communication needed for
                                    data exchange for a general
                                    sequence such as mixture of IID
                                    random variables as well as the
                                    optimal second-order asymptotic
                                    term in the minimum length of
                                    communication needed for data
                                    exchange for the IID random
                                    variables, when the probability of
                                    error is fixed.  This gives a
                                    precise characterization of the
                                    asymptotic reduction in the length
                                    of optimal communication due to
                                    interaction; in particular,
                                    two-sided Slepian-Wolf compression
                                    is strictly suboptimal.
                                    </p>
                                </li>
                                
                                
                                <li>
                                    With S. Watanabe, Impossibility
                                    Bounds for Secure Computing.
                                    <i>ISIT</i>, 2015.  <br />
                                    <abstract><a>[Abstract]</a> </abstract>
                                    <a href="papers/ht-sw15ii.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We derive impossibility (converse)
                                    bounds for the efficiency of
                                    implementing information
                                    theoretically secure oblivious
                                    transfer and bit commitment using
                                    correlated observations.  Our
                                    approach is based on relating
                                    these problems to that of testing
                                    if the observations of the parties
                                    are conditionally independent
                                    given the adversary's
                                    observation. The resulting bounds
                                    strengthen and improve upon
                                    several previously known results.
                                    
                                    </p>
                                </li>
                                
                                
                                <li>
                                    With P. Narayan and S. Watanabe,
                                    Common Randomness for Secure
                                    Computing.
                                    <i>ISIT</i>, 2015.  <br />
                                    <abstract><a>[Abstract]</a> </abstract>
                                    <a href="/papers/pn-ht-sw15.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We revisit A.C. Yao's classic
                                    problem of secure function
                                    computation by interactive
                                    communication, in an information
                                    theoretic setting.  Our approach,
                                    based on examining the underlying
                                    common randomness, provides a new
                                    proof of the characterization of a
                                    securely computable function by
                                    deterministic protocols. This
                                    approach also yields a
                                    characterization of the minimum
                                    communication needed for secure
                                    computability.
                                    </p>
                                </li>
                                
                                
                                
                                <li>
                                    With T. Javidi and Y. Kaspi,
                                    Gaussian Estimation under Attack
                                    Uncertainty.
                                    <i> ITW Jerusalem</i>, 2015.
                                    <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tj-yk-ht15.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We consider the estimation of a
                                    standard Gaussian random variable
                                    under an observation attack where
                                    an adversary may add a zero mean
                                    Gaussian noise with variance in a
                                    bounded, closed interval to an
                                    otherwise noiseless observation. A
                                    straightforward approach would
                                    entail either ignoring the attack
                                    and simply using an optimal
                                    estimator under normal operation
                                    or taking the worst-case attack
                                    into account and using a minimax
                                    estimator that minimizes the cost
                                    under the worst-case attack. In
                                    contrast, we seek to characterize
                                    the optimal tradeoff between the
                                    MSE under normal operation and the
                                    MSE under the worst-case
                                    attack. Equivalently, we seek a
                                    minimax estimator for any fixed
                                    prior probability of attack. Our
                                    main result shows that a unique
                                    minimax estimator exists for every
                                    fixed probability of attack and is
                                    given by the Bayesian estimator
                                    for a least-favorable prior on the
                                    set of possible
                                    variances. Furthermore, the
                                    least-favorable prior is unique
                                    and has a finite support. While
                                    the minimax estimator is linear
                                    when the probability of attack is
                                    0 or 1, our numerical results show
                                    that the minimax linear estimator
                                    is far from optimal for all other
                                    probabilities of attack and a
                                    simple nonlinear estimator does
                                    much better.
                                    </p>
                                </li>
                                
                                
                                
                                
                                <li> With J. Acharya, A. Orlitsky, and
                                A. T. Suresh, The Complexity of
                                Estimating Renyi Entropy.
                                    <i> SODA</i>, 2015.<br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/AcharyaOST14conf.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We study the number of independent
                                    samples from a $k$-symbol
                                    distribution needed to estimate
                                    its Renyi entropy of order a and
                                    show that super-linear (in $k$)
                                    samples are needed for $a < 1$,
                                    near linear $k$ samples are needed
                                    for noninteger $a>1$, but, perhaps
                                    surprisingly, for integer a>1 only
                                    $k^{1-1/a}$ samples suffice (upto
                                    constants).
                                        </p>
                                        </li>
                                
                                <li> With S. Watanabe, Converse
                                    Results for Secrecy Generation
                                    over Channels.
                                    <i> Invited, Asilomar</i>, 2014.
                                    <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/ht-sw-asilomar14.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We revisit the problem of secret
                                    key agreement in channel models,
                                    where in addition to a noisy,
                                    albeit secure channel, the
                                    terminals have access to a
                                    noiseless public commu- nication
                                    channel. We show a strong converse
                                    for the secret key capacity in the
                                    point-to-point model and give
                                    upper bounds for the general
                                    case. Underlying our proofs is a
                                    recently discovered single-shot
                                    converse for secret key rates in
                                    multiterminal source models.
                                    </p>
                                </li>
                                
                                <li> With M. Hayashi and S. Watanabe,
                                    Strong Converse for a Degraded
                                    Wiretap Channel via Active
                                    Hypothesis Testing.
                                    <i> Invited, Allerton</i>, 2014.
                                    <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/mh-ht-sw-allerton14.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We establish an upper bound on the
                                    rate of codes for a wiretap
                                    channel with public feedback for a
                                    fixed probability of error and
                                    secrecy parameter. As a corollary,
                                    we obtain a strong converse for
                                    the capacity of a degraded wiretap
                                    channel with public feedback. Our
                                    converse proof is based on a
                                    reduction of active hypothesis
                                    testing for discriminating between
                                    two channels to coding for wiretap
                                    channel with feedback.
                                    </p>
                                </li>
                                
                                <li> With A. Vardy, Explicit
                                    Capacity-Achieving Coding Scheme
                                    for the Gaussian Wiretap Channel.
                                    <i> ISIT</i>, 2014.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-vardy14.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We extend the Bellare-Tessaro
                                    coding scheme for a discrete,
                                    degraded, symmetric wiretap
                                    channel to a Gaussian wiretap
                                    channel. Denoting by SNR the
                                    signal-to-noise ratio of the
                                    eavesdropper's channel, the
                                    proposed scheme converts a
                                    transmission code of rate R for
                                    the channel of the legitimate
                                    receiver into a code of rate R -
                                    0.5 log(1 + SNR) for the Gaussian
                                    wiretap channel. The conversion
                                    has a <i>polynomial complexity</i>
                                    in the codeword length and the
                                    proposed scheme achieves <i>
                                    strong security</i>.  In
                                    particular, when the underlying
                                    transmission code is capacity
                                    achieving, this scheme achieves
                                    the secrecy capacity of the
                                    Gaussian wiretap channel.  In
                                    effect, this work allows us to
                                    convert any constructive scheme
                                    for transmitting over a Gaussian
                                    channel into a constructive scheme
                                    for the Gaussian wiretap channel.
                                    </p>
                                </li>
                                
                                
                                <li> With M. Hayashi and S. Watanabe,
                                    Secret Key Agreement: General
                                    Capacity and Second-Order
                                    Asymptotics.
                                    <i> ISIT</i>, 2014.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/hayashi-tyagi-watanabe14.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We revisit the problem of secret
                                    key agreement using interactive
                                    public communication for two
                                    parties.  When the underlying
                                    observations are independent and
                                    identically distributed, we
                                    establish the second-order
                                    asymptotic term in the maximum
                                    length of a secret
                                    key. Furthermore, for general
                                    observations, we establish the
                                    secret key capacity.  Underlying
                                    our proofs is a new secret key
                                    agreement scheme and a recently
                                    established upper bound on secret
                                    key lengths.
                                    </p>
                                </li>
                                
                                <li> With S. Watanabe, A Bound For
                                    Multiparty Secret Key Agreement
                                    And Implications For Problem Of
                                    Secure Computing.
                                    <i> EUROCRYPT</i>, 2014.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-watanabe14i.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We consider secret key agreement
                                    by multiple parties observing
                                    correlated data and communicating
                                    interactively over an insecure
                                    communication channel. Our main
                                    contribution is a single-shot
                                    upper bound on the length of the
                                    secret keys that can be generated,
                                    without making any assumptions on
                                    the distribution of the underlying
                                    data. Heuristically, we bound the
                                    secret key length in terms of
                                    ``how far'' is the joint
                                    distribution of the initial
                                    observations of the parties and
                                    the eavesdropper from a
                                    distribution that renders the
                                    observations of the parties
                                    conditionally independent across
                                    some partition, when conditioned
                                    on the eavesdropper's side
                                    information.  The closeness of the
                                    two distributions is measured in
                                    terms of the exponent of the
                                    probability of error of type II
                                    for a binary hypothesis testing
                                    problem, thus bringing out a
                                    structural connection between
                                    secret key agreement and binary
                                    hypothesis testing. When the
                                    underlying data consists of an
                                    independent and identically
                                    distributed sequence, an
                                    application of our bound recovers
                                    several known upper bounds for the
                                    asymptotic rate of a secret key
                                    that can be generated, without
                                    requiring the agreement error
                                    probability or the security index
                                    to vanish to 0 asymptotically.
                                    <br />
                                    
                                    Also, we consider the following
                                    problem of secure function
                                    computation with trusted parties:
                                    Multiple parties observing
                                    correlated data seek to compute a
                                    function of their collective
                                    data. To this end, they
                                    communicate interactively over an
                                    insecure communication channel. It
                                    is required that the value of the
                                    function be concealed from an
                                    eavesdropper with access to the
                                    communication. When is such a
                                    secure computation of a given
                                    function feasible? Using the
                                    aforementioned upper bound, we
                                    derive a necessary condition for
                                    the existence of a communication
                                    protocol that allows the parties
                                    to reliably recover the value of a
                                    given function, while keeping this
                                    value concealed from an
                                    eavesdropper with access to (only)
                                    the communication.
                                    </p>
                                </li>
                                
                                
                                <li> With S. Watanabe, Secret key
                                    capacity for multipleaccess
                                    channel with public feedback.
                                    <i> Invited, Allerton</i>, 2013.
                                    <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-watanabe13i.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We consider the generation of a
                                    secret key (SK) by the inputs and
                                    the output of a secure
                                    multipleaccess channel (MAC) that
                                    additionally have access to a
                                    noiseless public communication
                                    channel. Under specific
                                    restrictions on the protocols, we
                                    derive various upper bounds on the
                                    rate of such SKs. Specifically, if
                                    the public communication consists
                                    of only the feedback from the
                                    output terminal, then the rate of
                                    SKs that can be generated is
                                    bounded above by the maximum
                                    symmetric rate $R_f^*$ in the
                                    capacity region of the MAC with
                                    feedback. On the other hand, if
                                    the public communication is
                                    allowed only before and after the
                                    transmission over the MAC, then
                                    the rate of SKs is bounded above
                                    by the maximum symmetric rate
                                    $R^*$ in the capacity region of
                                    the MAC without
                                    feedback. Furthermore, for a
                                    symmetric MAC, we present a scheme
                                    that generates an SK of rate
                                    $R_f^*$, improving the best
                                    previously known achievable rate
                                    $R^*$. An application of our
                                    results establishes the SK
                                    capacity for adder MAC, without
                                    any restrictions on the protocols.
                                    </p>
                                </li>
                                
                                <li> With P. Narayan, How many queries
                                    will resolve common randomness?
                                    <i> ISIT</i>, 2013.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan13.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A set of m terminals, observing
                                    correlated signals, communicate
                                    interactively to generate common
                                    randomness for a given subset of
                                    them.  Knowing only the
                                    communication, how many direct
                                    queries of the value of the common
                                    randomness will resolve it? A
                                    general upper bound, valid for
                                    arbitrary signal alphabets, is
                                    developed for the number of such
                                    queries by using a query strategy
                                    that applies to all common
                                    randomness and associated
                                    communication. When the underlying
                                    signals are independent and
                                    identically distributed
                                    repetitions of m correlated random
                                    variables, the number of queries
                                    can be exponential in signal
                                    length. For this case, the
                                    mentioned upper bound is tight and
                                    leads to a single-letter formula
                                    for the largest query exponent,
                                    which coincides with the secret
                                    key capacity of a corresponding
                                    multiterminal source model. In
                                    fact, the upper bound constitutes
                                    a strong converse for the optimum
                                    query exponent, and implies also a
                                    new strong converse for secret key
                                    capacity. A key lemma, estimating
                                    the size of a large probability
                                    set in terms of R&egrave;nyi
                                    entropy, is interpreted separately
                                    also as a lossless block coding
                                    result for a general source. As a
                                    particularization, it yields the
                                    classic result for a discrete
                                    memoryless source.
                                    </p>
                                </li>
                                
                                
                                <li> With N. Kashyap,
                                    Y. Sankarasubramaniam, and
                                    K. Viswanathan, Fault-Tolerant
                                    Secret Key Generation.
                                    <i> ISIT</i>, 2012.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tksv12.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    Mobile nodes observing correlated
                                    data commu- nicate using an
                                    insecure bidirectional switch to
                                    generate a secret key, which
                                    remains concealed from the
                                    switch. We are interested in
                                    fault-tolerant secret key rates,
                                    i.e., the rates of secret key
                                    generated even if a subset of
                                    nodes drop out before the
                                    completion of the communication
                                    protocol. We formulate a new
                                    notion of fault-tolerant secret
                                    key capacity, and present an upper
                                    bound on it. This upper bound is
                                    shown to be tight when the random
                                    variables corresponding to the
                                    observations of nodes are
                                    exchangeable. Further, it is shown
                                    that one round of interaction
                                    achieves the fault-tolerant secret
                                    key capacity in this case. The
                                    upper bound is also tight for the
                                    case of a pairwise independent
                                    network model consisting of a
                                    complete graph, and can be
                                    attained by a noninteractive
                                    protocol.
                                    </p>
                                </li>
                                
                                <li> Distributed Computing With
                                Privacy
                                    <i> ISIT</i>, 2012.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi12.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A set of terminals that observe
                                    correlated data seek to compute
                                    functions of the data using
                                    interactive public commu-
                                    nication. At the same time it is
                                    required that this communication
                                    observed by an eavesdropper, does
                                    not reveal the value of a private
                                    function of the data. In general,
                                    the private function and the
                                    functions computed by the nodes
                                    can be all different. We show that
                                    a class of functions are securely
                                    computable if and only if the
                                    conditional entropy of data given
                                    the value of private function is
                                    greater than the least rate of
                                    interactive communication required
                                    for an appropriately chosen
                                    multiterminal source coding
                                    task. A single-letter formula is
                                    provided for this rate in special
                                    cases.
                                    </p>
                                </li>
                                
                                <li> Minimal public communication for
                                maximum rate secret key generation.
                                    <i> ISIT</i>, 2011.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi11.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    Secret key generation is
                                    considered for a pair of terminals
                                    that observe correlated sources
                                    and communicate interactively over
                                    a public channel. It is argued
                                    that optimum rate secret key
                                    generation is linked inherently to
                                    the Wyner's notion of common
                                    information between two dependent
                                    random variables. The minimum rate
                                    of interactive public
                                    communication required to generate
                                    an optimum rate secret key is
                                    characterized in terms of a
                                    variant of this notion of common
                                    information.
                                    </p>
                                </li>
                                
                                
                                <li> With P. Narayan and P. Gupta,
                                    When Is a Function Securely
                                    Computable?
                                    <i> ISIT</i>, 2011. (finalist for
                                    the Student Best Paper Award)
                                    <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan-gupta11ii.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    A subset of a set of terminals
                                    that observe correlated signals
                                    seek to compute a given function
                                    of the signals using public
                                    communication. It is required that
                                    the value of the function be kept
                                    secret from an eavesdropper with
                                    access to the communication. We
                                    show that the function is securely
                                    computable if and only if its
                                    entropy is less than the aided
                                    secret key capacity of an
                                    associated secrecy generation
                                    model, for which a single-letter
                                    characterization is provided.
                                    </p>
                                </li>
                                
                                <li> With P. Narayan and P. Gupta,
                                    Secure Computing.
                                    <i> ISIT</i>, 2010.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan-gupta10.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We study a problem of secure
                                    computation by multiple parties of
                                    a given function of their
                                    cumulative observations, using
                                    public communication but without
                                    revealing the value of the
                                    function to an eavesdropper with
                                    access to this communication. A
                                    Shannon theoretic formulation is
                                    introduced to characterize
                                    necessary and sufficient
                                    conditions for secure
                                    computability. Drawing on innate
                                    connections of this formulation to
                                    the problem of secret key
                                    generation by the same parties
                                    using public communication, we
                                    show that a function is securely
                                    computable if and only if its
                                    entropy is smaller than the secret
                                    key capacity. Conditions for
                                    secure computability at a lone
                                    terminal are also derived by
                                    association with an appropriate
                                    secret key generation problem.
                                    </p>
                                </li>
                                
                                <li> With P. Narayan, The
                                    Gelfand-Pinsker Channel: Strong
                                    Converse and Upper Bound for the
                                    Reliability Function.
                                    <i> ISIT</i>, 2009.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-narayan09.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We consider a Gelfand-Pinsker
                                    discrete memoryless channel (DMC)
                                    model and provide a strong
                                    converse for its capacity. The
                                    strong converse is then used to
                                    obtain an upper bound on the
                                    reliability function. Instrumental
                                    in our proofs is a new technical
                                    lemma which provides an upper
                                    bound for the rate of codes with
                                    codewords that are conditionally
                                    typical over large <i>message
                                    dependent</i> subsets of a typical
                                    set of state sequences. This
                                    technical result is a
                                    nonstraightforward analog of a
                                    known result for a DMC without
                                    states that provides an upper
                                    bound on the rate of a good code
                                    with codewords of a fixed type (to
                                    be found in, for instance, the
                                    Csisz&agrave;r-K&ouml;rner book
                                    </p>
                                </li>
                                
                                <li> With R. K. Mallik and S. Raina.
                                    Optimal Receiver for MPSK
                                    Signaling with Imperfect Channel
                                    Estimation.
                                    <i> WCNC</i>, 2007.  <br />
                                    <abstract><a>[Abstract]</a></abstract>
                                    <a href="papers/tyagi-mallik-raina07.pdf"
                                    target="_blank">[pdf]</a>
                                    <p class="abstract-text">
                                    We derive the structure of the
                                    opti- mal receiver for MPSK
                                    signaling over a correlated
                                    Rayleigh fading channel. The
                                    channel is estimated using the
                                    minimum mean square error
                                    criterion by means of pilot
                                    symbols. For the case of high
                                    signal-to-noise ratio, an
                                    approximate expression for the
                                    symbol error probability (SEP) of
                                    this scheme is obtained as an
                                    integral, and compared with the
                                    SEP of a suboptimal receiver which
                                    uses maximal- ratio
                                    combining. Numerical results show
                                    that the performance gap between
                                    the optimal and sub- optimal
                                    receivers increases with increase
                                    of the channel correlation and the
                                    number of diversity branches,
                                    whereas it decreases with increase
                                    of pilot-to-signal ratio
                                    </p>
                                </li>
                                
                            </ul>
                        </dd>
                    </div>
                </div>
                
                <div id="theses" class="row">
                  <div class="col-lg-8 col-lg-offset-2">
                    <h2>Theses</h2>
                    <dd>
                      <ul>
                        <li>
                          <b>Master's Thesis:</b> Optimal
                          Receivers for MPSK Signaling with
                          Imperfect Channel Estimation<br />
                          Indian Institute of Technology,
                          Delhi, 2007.<br />
                          <i>Supervisor: Prof. Ranjan
                            K. Mallik <br /><br />
                          </i>
                          
                        </li>
                        <li>
                          <b>PhD Dissertation:</b> Common
                          randomness principles of
                          secrecy<br /> University of
                          Maryland, College Park,
                          2013. <a href="papers/tyagi-thesis13.pdf"
                                   target="_blank">[pdf]</a>
                                    
                          <br />
                                    
                          <i>Supervisor: Prof. Prakash
                            Narayan<br /><br />
                            
                          </i>
                          
                        </li>
                        
                      </ul>
                      
		      
		    </dd>
		    <hr>
		  </div>
		</div>
        </section>

        <!-- Group -->
        <section id="students" class="students">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Group</h2>
			<ul> <i>Current members</i>
			  <li> Srinivas Daru (Intern, Summer 2018) [B.Tech. student at IIT KGP] </li>		
			  <li> Prerna Singh (Intern, Summer 2018) [B.Tech. student at AIT Pune] </li>		
			  <li> Vaishali P (Ph.D. student, Aug 2017-) [Jointly advised with
			    <a href="http://www.ece.iisc.ernet.in/~aditya/"
			  target="_blank">Aditya Gopalan</a> ]
			  </li>
			  <li> Soumya Subhra Banerjee (M. Tech. student, Aug 2016-)</li>
			  <li> Prathamesh Mayekar (Ph.D. student, Aug 2016-)</li>                        
			  <li> Lekshmi Ramesh (Ph.D. student, Aug
			    2015-) [Jointly advised with
			    <a href="http://www.ece.iisc.ernet.in/~cmurthy/"
			       target="_blank">Chandra Murthy</a> ]
			  </li>
                          <li> Sahasranand KR (Ph.D. student, Aug 2015-)
			  </li>
			  <li> Raghava GD (Ph.D. student, Aug 2015-)
			  </li>
			</ul>
			<ul> <i>Past members</i>
			  <li> Mishfad SV (Research assistant, October 2016-March 2018) [Ph.D. Student at University of Minnesota]</li>
			  <li> Ayush Jain (Intern, Summer 2017) [Ph.D. student at UCSD]</li>
			  <li> Pushpendu Ghosh (Intern, Summer 2017) [B.Tech. student at BITS Goa] </li>
			  <li> Rohit Chatterjee (UG student, Dec 2015 - Jun 2016) [Jointly advised with
                          <a href="http://drona.csa.iisc.ernet.in/~bhavana/"
                          target="_blank">Bhavana Kanukurthi</a> ]
			  </li>
			  <li> Srikanth Pai (Postdoctoral researcher, Dec 2015 - Oct 2016)</li>

			</ul>
                    </div>
		    <hr>
                </div>
            </div>
	</section>

        <!-- Students -->
        <section id="students" class="students">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Research Overview for Propective Students</h2>


			<p>I used to have a formal research blurb here
			which was reminiscent of a typical spiel a
			researcher gives to a prospective
			employer. But I think visitors of my webpage
			are usually prospective students. So I
			replaced the formal blurb with a more gassy version
			for prospective students who seek to join our
			``lab''. 
			</p>

			
		    </div>
		</div>

                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h3>What is information theory?</h3>
			<p>We work in Information Theory, an offspring
			of Probability Theory which has now come of
			age. Classical probability theory provides us
			a beautiful mathematical machinery to model
			and measure uncertainty and
			chance. Information theory goes one step
			beyond and quantizes what it means to have “a
			bit of information” about something. This
			ability to break information into small chunks
			makes Information Theory useful in a wide
			range of theoretical and practical
			applications. We are interested in
			understanding each of these applications; we
			have made a headway into a few. (To know more
			about the basics of information theory, you
			can take a look at the course notes
			above).</p> 
			
		    </div>
		</div>

                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h3>What do we do?</h3>
<p>Chartered as a mathematical theory of communication, Information Theory fueled the communication revolution and has guided most of the developments in communication systems. But surprisingly, the role of Information Theory in truly information centric technologies such as Artificial Intelligence and the Internet of Things has been limited. This is where we see an opportunity for us to come in. </p>

<p>Specifically, we study information theoretic formulations for problems involving interactive communication and distributed multi-agent systems, with all the hot topics such as cybersecurity, artificial intelligence, and IoT in mind. Often, we end-up solving a boring theoretical problem. Occasionally, we get some new insights into distinctive features of these problems. Sometimes, we can use these insights to do something useful. But seldom we do anything important.</p>
			
		    </div>
		</div>

                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h3>What have we been doing lately?</h3>
			<p>
			  Stuff like distributed and constrained
			  inference and optimization, minimal delay
			  compression and communication for CPS,
			  practical data exchange protocols,
			  compression of interactive communication,
			  secure computing, secret key agreement,
			  routing for MANETs, and sparse recovery
			  using covariance estimation. Go below and read our papers for more.  Besides these  
			  research problems, we are involved in
			   setting-up an air quality
			  monitoring (AQM) network in Electronic City area and a
			  5G compliant testbed for V2X communication.
			</p>

		    </div>
		</div>                   
  

		<div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h3>Openings</h3>
                        If you think you will fit the culture outlined
                        above and would like to join us, please send
                        an email to me with your CV
                        attached. Mention your overall GPA/percentage and include a list of
                        projects completed (in courses or otherwise). If you want to work on theoretical
                        problems, please include a list of
                        mathematically oriented courses done along
                        with the grades received. Unfortunately, I cannot reply to all
                        the emails I receive. But I will definitely
                        reply if your CV is a good fit. 
                        <hr>
                    </div>
                </div>



            </div>
        </section>





        <!-- Talks -->
        <section id="talks" class="talks">
            <div class="container-fluid">
                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                        <h2>Talks</h2>
                    </div>
                </div>
                <div class="row">
                  <div class="col-lg-8 col-lg-offset-2">
                    <h3>Talks with Videos</h3>
                    <dd>
                      <ul>
			
                        <li> Bombay Information Theory Seminar
                           (BITS) 2018 <br />
                          <i>Extra Samples Can Reduce
                            Communication for Independence
                            Testing.</i> <br /><br />
			  <iframe width="560" height="315"
				  src="https://www.youtube.com/embed/wExCh2Q3at8" frameborder="0"
				  allow="autoplay; encrypted-media" allowfullscreen></iframe>
			  <br /><br />
			</li>
			
                        <li> Institut Henri Poincar&egrave;,
                          Trimester on Nexus of Information and
                          Computing Theories, 2016 <br />
                          <i>Tutorial on Information
                            Theoretic Secrecy and Interactive
                            Communication.</i> <br /><br />
			  <iframe width="560" height="315"
				  src="https://www.youtube.com/embed/kjOL0U6t1-0" frameborder="0"
				  allowfullscreen></iframe> <br /><br />
			</li>
                                



                        <li> Simons Institute for Theory of
			  Computing, University of California Berkeley, Workshop on Information
			  Theory, Learning and Big Data, 2015 <br />
                          <i>Sample Complexity of Estimating
                            Entropy.</i> <br />
                          <a href="talks/talk_Simons.pdf"
                             target="_blank">[Slides]</a>
                          <br /><br />
			  <iframe width="560" height="315"
				  src="https://www.youtube.com/embed/UAuGnXoZlTQ" frameborder="0"
				  allowfullscreen></iframe> <br /><br />
                        </li>
          
                        
                        <li> Interactive Information Theory
                          Workshop, Banff International
                          Research Station, Canada, 2012
                          <br />
                          <i>Function Computation, Secrecy
                            Generation and Common
                            Randomness. </i> <br />
                          <a href="talks/talk_banff12.pdf"
                             target="_blank">[Slides]</a>
                          <br/><br/>
			  <iframe src="http://www.birs.ca/events/2012/5-day-workshops/12w5119/videos/embed/201201190915-Tyagi.mp4"
				  width="832" height="480" frameborder="0" allowfullscreen></iframe>
			  <br/><br/>
                        </li>
                      </ul>
                    </dd>
                  </div>
                </div>
                <div class="row">
                  <div class="col-lg-8 col-lg-offset-2">
                    <h3>Some Invited Talks and Tutorial</h3>
                    <dd>
                      <ul>
                        <li> Tutorial at ISIT 2017, delivered
                          jointly with Shun Watanabe.<br />
                          <i>Information theoretic
                            cryptography for information
                            theorists</i> <br />
                          <a href="talks/tutorial_ISIT17.pdf"
                             target="_blank">[Slides]</a> <a href="talks/tutorial_notes_ISIT17.pdf"
							     target="_blank">[Notes]</a>
			  


                        </li>
			
                                

                        <li> Indian Institute of Science, ECE
                          Faculty Seminar, 2016 <br />
                          <i>Universal Multiparty Data
                            Exchange.</i> <br />
                          <a href="talks/talk_ECE16.pdf"
                             target="_blank">[Slides]</a>
                        </li>

                        <li> Bombay Information Theory Seminar
                                (BITS) 2016
                          <i>Independence Testing Bound and
                            Interactive Communication</i>
                          <br />
                          <a href="talks/talk_BITS.pdf"
                             target="_blank">[Slides]</a>
                        </li>

                        <li>
                          University of Delaware; CyLab,
                          Carnegie Mellon University; UC San
                          Diego, 2014 <br />
                          <i> Converse Results for
                            Information Theoretic
                            Cryptography.</i> <br />
                          <a href="talks/talk_UCSD.pdf"
                             target="_blank">[Slides]</a>
                        </li>
                                
                        <li> Ph.D. Defense, University of
                          Maryland, College Park, 2013
                          <br />
                          <i> Common Randomness Principles
                            of Secrecy.</i> <br />
                          <a href="talks/talk_defense13.pdf"
                             target="_blank">[Slides]</a>
                        </li>
                                                        
                        <li> University of Illinois,
                          Urbana-Champaign, 2013 <br />
                          <i> How Many Queries Will Resolve
                            Common Randomness? </i> <br />
                          <a href="talks/talk_UIUC13.pdf"
                             target="_blank">[Slides]</a>
                        </li>
                                                        
                        <li> Hewlett Packard Labs, Bangalore,
                          India, 2012 <br />
                          <i> Secret Key Generation and
                            Secure Computing. </i> <br />
                          <a href="talks/talk_HPLabs.pdf"
                             target="_blank">[Slides]</a>
                        </li>
                      </ul>
                    </dd>
                  </div>
                </div>

                <div class="row">
                    <div class="col-lg-8 col-lg-offset-2">
                      <h3>Conference Talks</h3>
                      <dd>
                        <ul>
			  <li> NCC 2017
                            <i>Coding Theorems using Renyi
                              Information Measures.</i> <br />
                            <a href="talks/talk_NCC17.pdf"
                               target="_blank">[Slides]</a>
                          </li>
			  
			  <li> ISIT 2016
                            <i>Universal Multiparty Data
                              Exchange.</i> <br />
                            <a href="talks/talk_ISIT16.pdf"
                               target="_blank">[Slides]</a>
                          </li>

                          <li> ITCS 2016
                            <i>Information Complexity Density
                              and Simulation of Protocols</i>
                            <br />
                            <a href="talks/talk_ITCS16.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          
                          <li> ISIT 2015
                            <i>Interactive Communication for
                              Data Exchange</i> <br />
                            <a href="talks/talk_ISIT15.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> Simons Institute Workshop 2015
                            and NCC 2015
                            <i>Sample Complexity of Estimating
                              Entropy</i> <br />
                            <a href="talks/talk_simons15.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> Allerton 2014
                            <i>Strong Converse for a Degraded
                              Channel via Active Hypothesis
                              Testing</i> <br />
                            <a href="talks/talk_Allerton14.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> ISIT 2014
                            <i> Explicit capacity achieving
                              codes for the Gaussian wiretap
                                        channel <br />
                            </i><a href="talks/talk_ISIT14ii.pdf"
                                   target="_blank">[Slides]</a>
                          </li>
                          
                          <li> ISIT 2014
                            <i> Secret Key Agreement: General
                              Capacity and Second-Order
                              Asymptotics <br />
                            </i><a href="talks/talk_ISIT14i.pdf"
                                   target="_blank">[Slides]</a>
                          </li>
                          
			  <li> EUROCRYPT 2014
			    <i>A Bound for Multiparty Secret
                              Key Agreement and Implications for
                              a Problem of Secure Computing</i>
                            <br />
                            <a href="talks/talk_EUROCRYPT14.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> CISS 2014
                            <i>A Converse For Secret Key
                              Agreement</i> <br />
                            <a href="talks/talk_CISS14.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                          
                          <li> ITA 2014
                            <i>A Bound on Secret Key Length
                              via Binary Hypothesis
                              Testing. </i> <br />
                            <a href="talks/talk_ITA14.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> Allerton 2013
                            <i>Secret Key Capacity for
                              Multipleaccess Channel with Public
                              Feedback. </i> <br />
                            <a href="talks/talk_Allerton13.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> ISIT 2013
                            <i>How Many Queries Will Resolve
                              Common Randomness? </i> <br />
                            <a href="talks/talk_ISIT13.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                          
                          <li> ISIT 2012
                            <i>Fault Tolerant Secret Key
                              Generation. </i> <br />
                            <a href="talks/talk_ISIT12i.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> ISIT 2011
                            <i>Minimal Public Communication
                              for Maximum Rate Secret Key
                              Generation. </i> <br />
                            <a href="talks/talk_ISIT11ii.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                                          
                          <li> ISIT 2011
                            <i>When is a Function Securely
                              Computable?</i>  <br />
                            <a href="talks/talk_ISIT11i.pdf"
                               target="_blank">[Slides]</a>
                          </li>
                                
                          <li> ISIT 2009
                            <i>The Gelfand-Pinsker Channel:
                              Strong Converse and Upper Bound
                              for the Reliability Function.</i>
                            <br />
                            <a href="talks/talk_ISIT09.pdf"
                               target="_blank">[Slides]</a>
                          </li>                                                              
                        </ul>
                      </dd>
                    </div>                    		    
		</div>
		<hr>
            </div>            
        </section>




        
        <!-- jQuery -->
        <script src="js/jquery.js"></script>
        
        <!-- Smooth Scrolling -->
        <script src="js/jquery.easing.min.js"></script>
        <script src="js/scrolling-nav.js"></script>

        <!-- Bootstrap Core JavaScript -->
        <script src="js/bootstrap.min.js"></script>

        
        
        <!-- Latex -->
        <script type="text/x-mathjax-config">
            MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'],
            ['\\(','\\)']]}});
            </script>
        <script type="text/javascript"
            src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
            </script>
        
        <!-- Abstract -->
        <script type="text/javascript">
            $(document).ready(function(){
                              $("abstract").click(function(){
                              $(this).next().next().slideToggle(300);
                              }); });
            </script>
        
    </body>
    
</html> 
